grw$gr.arg.name <- names(formals(grw$gr))[2]
grw$gr.args <- if (is.empty.list(gr.args)) list() else gr.args
grw$par.prev <- c()
grw$n <- 0
grw$A <- matrix()
grw$AA <- matrix()
grw$enable <- .enable
grw$verbose <- .verbose
grw$step.len <- 0.001
grw$eps.sd <- .Machine$double.eps^(1/5)
grw$iter <- 0
grw.par <- grw
MGS <- function(G) {
n <- dim(G)[1]
q <- numeric(n)
for (i in 1:n) {
r <- sqrt(sum(G[,i]*G[,i]))
q <- G[,i]/r
G[,i] <- q
if ((i + 1) <= n) {
for (j in (i + 1):n) {
r <- sum(q * G[,j])
G[,j] <- G[,j] - r*q
}
}
}
return(G)
}
gradient <- function(par, ...) {
gr.args <- list(...)
grw <<- grw.par
grw$iter <- grw$iter + 1
first.time <- FALSE
if (grw$n == 0) {
first.time <- TRUE
grw$par.prev <- par
grw$n <- length(par)
if (grw$enable) {
grw$A <- matrix(rnorm(grw$n^2, sd = grw$eps.sd), grw$n, grw$n)
diag(grw$A) <- diag(grw$A) + 1
} else {
grw$A <- diag(grw$n)
}
grw$AA <- grw$A
}
if (!first.time && grw$enable) {
grw$A[, 2:grw$n] <- grw$A[, 1:(grw$n-1)]
dpar <- scale(par - grw$par.prev)
grw$A[, 1] <- dpar + rnorm(grw$n, sd = grw$eps.sd)
grw$par.prev <- par
grw$AA <- MGS(grw$A)
if (grw$verbose) {
print(paste0("Iteration: ", grw$iter))
rownames(grw$AA) <- paste0("par", 1:grw$n)
colnames(grw$AA) <- paste0("dir", 1:grw$n)
print(round(dig = 2, grw$AA))
}
}
grw$par <- par
tmp.fn <- function(x) {
dpar <- drop(grw$AA %*% x)
x <- grw$par + dpar
args <- c(list(x), grw$fn.args)
nm <- names(args)
nm[1] <- grw$fn.arg.name
names(args) <- nm
return (do.call(grw$fn, args = args))
}
x <- rep(0, grw$n)
args <- c(tmp.fn, list(x), grw$gr.args, ...)
nm <- names(args)
nm[1:2] <- c("", grw$gr.arg.name)
names(args) <- nm
gg <- do.call(grw$gr, args = args)
grad <- solve(t(grw$AA), gg)
grw.par <<- grw
return(grad)
}
return(gradient)
})
return (fun)
}
## I add an argument here, just to make sure it passes through correctly...
f1 <- function(x, AA = 6) {
stopifnot(AA == 7)
res = 0.0
for(i in 1:(length(x)-1))
res = res + 100*(x[i+1] - x[i]^2)^2 + (1-x[i])^2
return(res)
}
## need to pass AA=7
if (TRUE) {
## use simple estimates
g1.new <- gr.wrapper(f1, .enable = TRUE, .verbose = FALSE, AA = 7, gr.args = list(step.size = 0.00099))
g1.plain <- gr.wrapper(f1, .enable = FALSE, AA = 7)
} else {
## use good estimates
library(numDeriv)
g1.new <- gr.wrapper(f1, gr = grad, .enable = TRUE, .verbose = FALSE, AA = 7)
g1.plain <- gr.wrapper(f1, gr = grad, .enable = FALSE, AA = 7)
}
g1 <- function(x, ...) {
n <- length(x)
g <- numeric(n)
for(i in 1:(n-1)) {
g[i] <- g[i] -400 * x[i] * (x[i+1] - x[i]^2) - 2 * (1 - x[i])
g[i+1] <- g[i+1] + 200 * (x[i+1] - x[i]^2)
}
err.new <- mean(abs(g - g1.new(x)))
err.default <- mean(abs(g - g1.plain(x)))
##print(round(dig = 6, c(err.new = err.new, err.default = err.default, ratio = err.new/err.default)))
G <- get("Global", envir = .GlobalEnv)
G$err.trace <- c(G$err.trace, err.new - err.default)
G$default.trace <- c(G$default.trace, err.default)
G$new.trace <- c(G$new.trace, err.new)
assign("Global", G, envir = .GlobalEnv)
return (g)
}
Global <- list(err.trace = c(), default.trace = c(), new.trace = c())
dim <- 5
x_initial = rnorm(dim, mean = 1, sd = 2)
r.opt <- stats::optim(x_initial, f1, g1, method = "BFGS", control = list(maxit = 100000), AA = 7)
print(r.opt$value)
print(r.opt$par)
plot(Global$new.trace, pch = 19, log = "y", type = "l", lwd = 3, col = "blue")
lines(Global$default.trace, lwd = 3, lty = 2, col = "red")
gr.wrapper <- function(fn = NULL, gr = NULL, gr.args = list(), ...,
.enable = TRUE, .verbose = FALSE)
{
## '...' are optional arguments to 'fn'
## 'gr' is an optional generic gradient function of type: gr(fun, x, gr.args)
stopifnot(!is.null(fn))
is.empty.list <- function(a) {
if (!(is.null(a) || is.list(a))) {
## wrong format, ignore
return (TRUE)
}
return (is.null(a) || (is.list(a) && length(a) == 0))
}
fun <- local({
gr.grad.default <- function(fun, x, step.size = 0.001, ...) {
gr.args <- list(...)
n <- length(x)
grad <- numeric(n)
e <- rep(0, n)
for(i in 1:n) {
e[] <- 0
e[i] <- 1
grad[i] <- (fun(x + step.size * e) - fun(x - step.size * e)) / (2 * step.size)
}
return (grad)
}
grw <- list()
grw$fn <- fn
grw$fn.arg.name <- names(formals(fn))[1]
grw$fn.args <- list(...)
grw$gr <- if (is.null(gr)) gr.grad.default else gr
grw$gr.arg.name <- names(formals(grw$gr))[2]
grw$gr.args <- if (is.empty.list(gr.args)) list() else gr.args
grw$par.prev <- c()
grw$n <- 0
grw$A <- matrix()
grw$AA <- matrix()
grw$enable <- .enable
grw$verbose <- .verbose
grw$step.len <- 0.001
grw$eps.sd <- .Machine$double.eps^(1/5)
grw$iter <- 0
grw.par <- grw
MGS <- function(G) {
n <- dim(G)[1]
q <- numeric(n)
for (i in 1:n) {
r <- sqrt(sum(G[,i]*G[,i]))
q <- G[,i]/r
G[,i] <- q
if ((i + 1) <= n) {
for (j in (i + 1):n) {
r <- sum(q * G[,j])
G[,j] <- G[,j] - r*q
}
}
}
return(G)
}
gradient <- function(par, ...) {
gr.args <- list(...)
grw <<- grw.par
grw$iter <- grw$iter + 1
first.time <- FALSE
if (grw$n == 0) {
first.time <- TRUE
grw$par.prev <- par
grw$n <- length(par)
if (grw$enable) {
grw$A <- matrix(rnorm(grw$n^2, sd = grw$eps.sd), grw$n, grw$n)
diag(grw$A) <- diag(grw$A) + 1
} else {
grw$A <- diag(grw$n)
}
grw$AA <- grw$A
}
if (!first.time && grw$enable) {
grw$A[, 2:grw$n] <- grw$A[, 1:(grw$n-1)]
dpar <- scale(par - grw$par.prev)
grw$A[, 1] <- dpar + rnorm(grw$n, sd = grw$eps.sd)
grw$par.prev <- par
grw$AA <- MGS(grw$A)
if (grw$verbose) {
print(paste0("Iteration: ", grw$iter))
rownames(grw$AA) <- paste0("par", 1:grw$n)
colnames(grw$AA) <- paste0("dir", 1:grw$n)
print(round(dig = 2, grw$AA))
}
}
grw$par <- par
tmp.fn <- function(x) {
dpar <- drop(grw$AA %*% x)
x <- grw$par + dpar
args <- c(list(x), grw$fn.args)
nm <- names(args)
nm[1] <- grw$fn.arg.name
names(args) <- nm
return (do.call(grw$fn, args = args))
}
x <- rep(0, grw$n)
args <- c(tmp.fn, list(x), grw$gr.args, ...)
nm <- names(args)
nm[1:2] <- c("", grw$gr.arg.name)
names(args) <- nm
gg <- do.call(grw$gr, args = args)
grad <- solve(t(grw$AA), gg)
grw.par <<- grw
return(grad)
}
return(gradient)
})
return (fun)
}
## I add an argument here, just to make sure it passes through correctly...
f1 <- function(x, AA = 6) {
stopifnot(AA == 7)
res = 0.0
for(i in 1:(length(x)-1))
res = res + 100*(x[i+1] - x[i]^2)^2 + (1-x[i])^2
return(res)
}
## need to pass AA=7
if (TRUE) {
## use simple estimates
g1.new <- gr.wrapper(f1, .enable = TRUE, .verbose = FALSE, AA = 7, gr.args = list(step.size = 0.00099))
g1.plain <- gr.wrapper(f1, .enable = FALSE, AA = 7)
} else {
## use good estimates
library(numDeriv)
g1.new <- gr.wrapper(f1, gr = grad, .enable = TRUE, .verbose = FALSE, AA = 7)
g1.plain <- gr.wrapper(f1, gr = grad, .enable = FALSE, AA = 7)
}
g1 <- function(x, ...) {
n <- length(x)
g <- numeric(n)
for(i in 1:(n-1)) {
g[i] <- g[i] -400 * x[i] * (x[i+1] - x[i]^2) - 2 * (1 - x[i])
g[i+1] <- g[i+1] + 200 * (x[i+1] - x[i]^2)
}
err.new <- mean(abs(g - g1.new(x)))
err.default <- mean(abs(g - g1.plain(x)))
##print(round(dig = 6, c(err.new = err.new, err.default = err.default, ratio = err.new/err.default)))
G <- get("Global", envir = .GlobalEnv)
G$err.trace <- c(G$err.trace, err.new - err.default)
G$default.trace <- c(G$default.trace, err.default)
G$new.trace <- c(G$new.trace, err.new)
assign("Global", G, envir = .GlobalEnv)
return (g)
}
Global <- list(err.trace = c(), default.trace = c(), new.trace = c())
dim <- 5
x_initial = rnorm(dim, mean = 1, sd = 2)
r.opt <- stats::optim(x_initial, f1, g1, method = "BFGS", control = list(maxit = 100000), AA = 7)
print(r.opt$value)
print(r.opt$par)
plot(Global$new.trace, pch = 19, log = "y", type = "l", lwd = 3, col = "blue")
lines(Global$default.trace, lwd = 3, lty = 2, col = "red")
gr.wrapper <- function(fn = NULL, gr = NULL, gr.args = list(), ...,
.enable = TRUE, .verbose = FALSE)
{
## '...' are optional arguments to 'fn'
## 'gr' is an optional generic gradient function of type: gr(fun, x, gr.args)
stopifnot(!is.null(fn))
is.empty.list <- function(a) {
if (!(is.null(a) || is.list(a))) {
## wrong format, ignore
return (TRUE)
}
return (is.null(a) || (is.list(a) && length(a) == 0))
}
fun <- local({
gr.grad.default <- function(fun, x, step.size = 0.001, ...) {
gr.args <- list(...)
n <- length(x)
grad <- numeric(n)
e <- rep(0, n)
for(i in 1:n) {
e[] <- 0
e[i] <- 1
grad[i] <- (fun(x + step.size * e) - fun(x - step.size * e)) / (2 * step.size)
}
return (grad)
}
grw <- list()
grw$fn <- fn
grw$fn.arg.name <- names(formals(fn))[1]
grw$fn.args <- list(...)
grw$gr <- if (is.null(gr)) gr.grad.default else gr
grw$gr.arg.name <- names(formals(grw$gr))[2]
grw$gr.args <- if (is.empty.list(gr.args)) list() else gr.args
grw$par.prev <- c()
grw$n <- 0
grw$A <- matrix()
grw$AA <- matrix()
grw$enable <- .enable
grw$verbose <- .verbose
grw$step.len <- 0.001
grw$eps.sd <- .Machine$double.eps^(1/5)
grw$iter <- 0
grw.par <- grw
MGS <- function(G) {
n <- dim(G)[1]
q <- numeric(n)
for (i in 1:n) {
r <- sqrt(sum(G[,i]*G[,i]))
q <- G[,i]/r
G[,i] <- q
if ((i + 1) <= n) {
for (j in (i + 1):n) {
r <- sum(q * G[,j])
G[,j] <- G[,j] - r*q
}
}
}
return(G)
}
gradient <- function(par, ...) {
gr.args <- list(...)
grw <<- grw.par
grw$iter <- grw$iter + 1
first.time <- FALSE
if (grw$n == 0) {
first.time <- TRUE
grw$par.prev <- par
grw$n <- length(par)
if (grw$enable) {
grw$A <- matrix(rnorm(grw$n^2, sd = grw$eps.sd), grw$n, grw$n)
diag(grw$A) <- diag(grw$A) + 1
} else {
grw$A <- diag(grw$n)
}
grw$AA <- grw$A
}
if (!first.time && grw$enable) {
grw$A[, 2:grw$n] <- grw$A[, 1:(grw$n-1)]
dpar <- scale(par - grw$par.prev)
grw$A[, 1] <- dpar + rnorm(grw$n, sd = grw$eps.sd)
grw$par.prev <- par
grw$AA <- MGS(grw$A)
if (grw$verbose) {
print(paste0("Iteration: ", grw$iter))
rownames(grw$AA) <- paste0("par", 1:grw$n)
colnames(grw$AA) <- paste0("dir", 1:grw$n)
print(round(dig = 2, grw$AA))
}
}
grw$par <- par
tmp.fn <- function(x) {
dpar <- drop(grw$AA %*% x)
x <- grw$par + dpar
args <- c(list(x), grw$fn.args)
nm <- names(args)
nm[1] <- grw$fn.arg.name
names(args) <- nm
return (do.call(grw$fn, args = args))
}
x <- rep(0, grw$n)
args <- c(tmp.fn, list(x), grw$gr.args, ...)
nm <- names(args)
nm[1:2] <- c("", grw$gr.arg.name)
names(args) <- nm
gg <- do.call(grw$gr, args = args)
grad <- solve(t(grw$AA), gg)
grw.par <<- grw
return(grad)
}
return(gradient)
})
return (fun)
}
## I add an argument here, just to make sure it passes through correctly...
f1 <- function(x, AA = 6) {
stopifnot(AA == 7)
res = 0.0
for(i in 1:(length(x)-1))
res = res + 100*(x[i+1] - x[i]^2)^2 + (1-x[i])^2
return(res)
}
## need to pass AA=7
# if (TRUE) {
#   ## use simple estimates
#   g1.new <- gr.wrapper(f1, .enable = TRUE, .verbose = FALSE, AA = 7, gr.args = list(step.size = 0.00099))
#   g1.plain <- gr.wrapper(f1, .enable = FALSE, AA = 7)
# } else {
## use good estimates
library(numDeriv)
g1.new <- gr.wrapper(f1, gr = grad, .enable = TRUE, .verbose = FALSE, AA = 7)
g1.plain <- gr.wrapper(f1, gr = grad, .enable = FALSE, AA = 7)
#}
g1 <- function(x, ...) {
n <- length(x)
g <- numeric(n)
for(i in 1:(n-1)) {
g[i] <- g[i] -400 * x[i] * (x[i+1] - x[i]^2) - 2 * (1 - x[i])
g[i+1] <- g[i+1] + 200 * (x[i+1] - x[i]^2)
}
err.new <- mean(abs(g - g1.new(x)))
err.default <- mean(abs(g - g1.plain(x)))
##print(round(dig = 6, c(err.new = err.new, err.default = err.default, ratio = err.new/err.default)))
G <- get("Global", envir = .GlobalEnv)
G$err.trace <- c(G$err.trace, err.new - err.default)
G$default.trace <- c(G$default.trace, err.default)
G$new.trace <- c(G$new.trace, err.new)
assign("Global", G, envir = .GlobalEnv)
return (g)
}
Global <- list(err.trace = c(), default.trace = c(), new.trace = c())
dim <- 5
x_initial = rnorm(dim, mean = 1, sd = 2)
r.opt <- stats::optim(x_initial, f1, g1, method = "BFGS", control = list(maxit = 100000), AA = 7)
print(r.opt$value)
print(r.opt$par)
plot(Global$new.trace, pch = 19, log = "y", type = "l", lwd = 3, col = "blue")
lines(Global$default.trace, lwd = 3, lty = 2, col = "red")
library(numDeriv)
grad
rrrr = smartGrad::optim(par, fn=myfun,
gr = grad,
method = c("BFGS"),
hessian = FALSE)
myfun <- function(x) {
res = 0.0
for(i in 1:(length(x)-1))
res = res + 100*(x[i+1] - x[i]^2)^2 + (1-x[i])^2
return(res)
}
mygrad <- function(x) {
step.size = 0.001
n <- length(x)
grad <- numeric(n)
e <- rep(0, n)
for(i in 1:n) {
e[] <- 0
e[i] <- 1
grad[i] <- (f1(x + step.size * e) - f1(x - step.size * e)) / (2 * step.size)
}
return (grad)
}
par = rnorm(2,0,2)
r = stats::optim(par, fn=myfun,
gr = mygrad,
method = c("BFGS"),
hessian = FALSE)
r$par
library(numDeriv)
grad
rrrr = smartGrad::optim(par, fn=myfun,
gr = grad,
method = c("BFGS"),
hessian = FALSE)
grad
rrrr
mygrad <- function(x) {
step.size = 0.001
n <- length(x)
grad <- numeric(n)
e <- rep(0, n)
for(i in 1:n) {
e[] <- 0
e[i] <- 1
grad[i] <- (f1(x + step.size * e) - f1(x - step.size * e)) / (2 * step.size)
}
return (grad)
}
grad
rrrr = smartGrad::optim(par, fn=myfun,
gr = mygrad,
method = c("BFGS"),
hessian = FALSE)
mygrad <- function(x,f1) {
step.size = 0.001
n <- length(x)
grad <- numeric(n)
e <- rep(0, n)
for(i in 1:n) {
e[] <- 0
e[i] <- 1
grad[i] <- (f1(x + step.size * e) - f1(x - step.size * e)) / (2 * step.size)
}
return (grad)
}
grad
rrrr = smartGrad::optim(par, fn=myfun,
gr = mygrad,
method = c("BFGS"),
hessian = FALSE)
